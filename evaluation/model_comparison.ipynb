{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ae867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(image, n_rows, n_cols, i_plot, binary = False, show = False, title = '', no_other_class_indexes = [1, 2, 3, 4, 5]):\n",
    "    plt.subplot(n_rows, n_cols, i_plot)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title)\n",
    "    \n",
    "    if image.ndim < 3:\n",
    "        if not binary:\n",
    "            pred_shape = image.shape + (3,)\n",
    "            prediction = (0xff, 0xff, 0xff) * np.ones(pred_shape)\n",
    "            prediction[image == no_other_class_indexes[0]]  = (0x00, 0xff, 0xff) # Calcita\n",
    "            prediction[image == no_other_class_indexes[1]]  = (0x00, 0x70, 0xc0) # Dolomita\n",
    "            prediction[image == no_other_class_indexes[2]]  = (0xda, 0xa5, 0x20) # Mg-Argilominerais\n",
    "            prediction[image == no_other_class_indexes[3]]  = (0x63, 0x63, 0x63) # Poros\n",
    "            prediction[image == no_other_class_indexes[4]]  = (0xff, 0xff, 0x00) # Quartzo\n",
    "            #prediction[np.where(image not in no_other_class_indexes)] = (0xff, 0xff, 0xff) # Outros\n",
    "            plt.imshow(prediction/255.0)\n",
    "        else:\n",
    "            plt.imshow(image, cmap = 'gray')\n",
    "    else:\n",
    "        image_as_numpy = np.moveaxis(image.numpy(), 0, -1)\n",
    "        #n_images = image_as_numpy.shape[-1]//3\n",
    "        #plt.subplot(1, n_images, 1)\n",
    "        plt.imshow(image_as_numpy[:, :, :3])\n",
    "        #if n_images == 2:\n",
    "        #    plt.subplot(1, n_images, 2)\n",
    "        #    plt.imshow(image_as_numpy[:, :, 3:])\n",
    "        '''\n",
    "        plt.axis('off')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(image_as_numpy[:, :, :3])\n",
    "        plt.savefig('poros.png', bbox_inches = 'tight', pad_inches = 0, dpi = 34.7)\n",
    "        #plt.show()\n",
    "        #plt.axis('off')\n",
    "        #plt.xticks([])\n",
    "        #plt.yticks([])\n",
    "        #plt.imshow(image_as_numpy[:, :, 3:])\n",
    "        #plt.savefig('poros.png', bbox_inches = 'tight', pad_inches = 0)\n",
    "        '''\n",
    "    \n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = None # 0: cluster 0; 1: cluster 1; None: full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730009bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(os.sep, 'petrobr', 'parceirosbr', 'smartseg', 'thinsection', 'qemscan', 'models')\n",
    "\n",
    "if cluster_model is None:\n",
    "    saved_model = {\n",
    "        'old': 'smartseg_thinsection_completo.pth',\n",
    "        'new': 'aa30a928c34e4fbd99f46c7b.pth'\n",
    "    }\n",
    "elif cluster_model == 0:\n",
    "    saved_model = 'smartseg_thinsection_texturafina.pth'\n",
    "elif cluster_model == 1:\n",
    "    saved_model = 'smartseg_thinsection_texturadensa.pth'\n",
    "    \n",
    "in_channels = 6\n",
    "out_channels = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0936d",
   "metadata": {},
   "source": [
    "Utilizando aqui os recursos do MONAI para carregar uma imagem aleatória de exemplo. Este bloco pode ser substituído por qualquer rotina que gere uma imagem de entrada do tipo Tensor PyTorch na forma (Canais, Altura, Largura)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from monai.utils import first\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.transforms import Compose, LoadImaged, AsChannelFirstd, ScaleIntensityRanged, EnsureTyped\n",
    "\n",
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys = ['image', 'label']),\n",
    "        AsChannelFirstd(keys = ['image']),\n",
    "        ScaleIntensityRanged(keys = ['image'], a_min = 0, a_max = 255, b_min = 0.0, b_max = 1.0, clip = True),\n",
    "        EnsureTyped(keys = ['image', 'label'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_images = ['FL/5400.25', 'SC/6398.50t', 'SC/6390.00t', 'SC/6355.00t', 'SC/6346.60t', 'SC/6340.50t', 'SA/6292.50', 'AR/6381.90',\n",
    "              'AR/6380.45', 'AR/6378.05', 'AR/6376.65', 'AR/6374.95', 'M/5219.38', 'M/5168.05', 'M/5236.95', 'FL/5400.55',\n",
    "              'LB/5477.70', 'YB/4822.00', 'SL/5174.50', 'AS/5675.70', 'AS/5672.00']\n",
    "data_paths_regex  = os.path.join(os.sep, 'petrobr', 'parceirosbr', 'smartseg', 'datasets', 'qemscan', 'generated', \\\n",
    "                                    '*', '*', '10000x10000' + '_nii.gz', 'data',   '*.nii.gz')\n",
    "label_paths_regex = data_paths_regex.replace('data' + os.sep, 'labels' + os.sep)\n",
    "data_paths  = glob.glob(data_paths_regex)\n",
    "label_paths = glob.glob(label_paths_regex)\n",
    "data_paths = [{'image': dpath, 'label': lpath} for dpath, lpath in zip(data_paths, label_paths) if any(image in dpath for image in test_images)]\n",
    "dataset = Dataset(data = data_paths, transform = transforms)\n",
    "data_loader = DataLoader(dataset = dataset, shuffle = True)\n",
    "#input = first(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d782d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet(spatial_dims = 2, in_channels = in_channels, out_channels = out_channels, channels = (16, 32, 64, 128, 256), \\\n",
    "             strides = (2, 2, 2, 2), num_res_units = 2, norm = Norm.BATCH)\n",
    "\n",
    "output = {}\n",
    "\n",
    "for input in data_loader:\n",
    "    for age in ['old', 'new']:\n",
    "        model.load_state_dict(\n",
    "            torch.load(os.path.join(model_dir, saved_model[age]))\n",
    "        )\n",
    "        _ = model.eval()\n",
    "\n",
    "        output[age] = model(input['image'])#sliding_window_inference(inputs = input['image'], roi_size = (512, 512), sw_batch_size = 4, predictor = model)\n",
    "        output[age] = torch.argmax(output[age][:, 1:], dim = 1)[0].float() + 1\n",
    "        \n",
    "    info = input['image_meta_dict']['filename_or_obj'][0].split(os.sep)\n",
    "    im_name = info[7] + '_' + info[8]\n",
    "    plt.suptitle(im_name)\n",
    "    break\n",
    "    plot(input['image'][0], 2, 2, 1, title = 'Image')\n",
    "    plot(input['label'][0], 2, 2, 2, title = 'Label', no_other_class_indexes = [4, 6, 25, 14, 15])\n",
    "    plot(output['old'], 2, 2, 3, title = 'Old prediction')\n",
    "    plot(output['new'], 2, 2, 4, title = 'New prediction', show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffbacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet(spatial_dims = 2, in_channels = in_channels, out_channels = out_channels, channels = (16, 32, 64, 128, 256), \\\n",
    "             strides = (2, 2, 2, 2), num_res_units = 2, norm = Norm.BATCH)\n",
    "\n",
    "output = {}\n",
    "\n",
    "for input in data_loader:\n",
    "    for age in ['old', 'new']:\n",
    "        model.load_state_dict(\n",
    "            torch.load(os.path.join(model_dir, saved_model[age]))\n",
    "        )\n",
    "        _ = model.eval()\n",
    "\n",
    "        output[age] = model(input['image'])#sliding_window_inference(inputs = input['image'], roi_size = (512, 512), sw_batch_size = 4, predictor = model)\n",
    "        output[age] = torch.argmax(output[age][:, 1:], dim = 1)[0].float() + 1\n",
    "        \n",
    "    info = input['image_meta_dict']['filename_or_obj'][0].split(os.sep)\n",
    "    im_name = info[7] + '_' + info[8]\n",
    "    plt.suptitle(im_name)\n",
    "    break\n",
    "    plot(input['image'][0], 2, 2, 1, title = 'Image')\n",
    "    plot(input['label'][0], 2, 2, 2, title = 'Label', no_other_class_indexes = [4, 6, 25, 14, 15])\n",
    "    plot(output['old'], 2, 2, 3, title = 'Old prediction')\n",
    "    plot(output['new'], 2, 2, 4, title = 'New prediction', show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094451b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
