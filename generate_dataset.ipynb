{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import glob\n",
    "import nrrd\n",
    "import shutil\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tifffile as tif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from netCDF4 import Dataset\n",
    "from skimage.transform import resize as sk_resize\n",
    "from matplotlib.colors import Normalize\n",
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32171e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(title, image):\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41462d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_nc_file_name(group, value):\n",
    "    if group == 'Siliciclastics':\n",
    "        return value + '.nc'\n",
    "    return group + '_' + value + '.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd21bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(image, unified_labels, type):\n",
    "    rgb = np.stack((image, image, image), axis = 2)\n",
    "    for i in unified_labels[unified_labels['type'] == type].index:\n",
    "        remap_indexes = np.where(image == i)\n",
    "        color = unified_labels.loc[i, 'color_hex']\n",
    "        rgb[remap_indexes] = np.array([[int(color[1:3], 16), int(color[3:5], 16), int(color[5: ], 16)]])/255.0\n",
    "    \n",
    "    return rgb\n",
    "\n",
    "def imshow_mini(image, axis, title, unified_labels, remap_colors = False, cmap = None):\n",
    "    axis.set_title(title)\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "    axis.imshow(cv2.resize(image if not remap_colors else remap(image, unified_labels, type = 'ec' if 'E.C.' in title else 'qemscan'), (0, 0), fx = 1/10, fy = 1/10), cmap = cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proportions(proportions, unified_labels, title = ''):\n",
    "    os.makedirs('proportions', exist_ok = True)\n",
    "    unified_minerals = unified_labels[unified_labels['type'] == 'qemscan'] \n",
    "    \n",
    "    for element in proportions.index:\n",
    "        bar_color = unified_minerals[unified_minerals['Element'] == element]['color_hex'].values\n",
    "        plt.bar(x = element, height = proportions[element],\n",
    "                color = bar_color if element != 'Desconhecido' else 'black',\n",
    "               edgecolor = None if bar_color != '#ffffff' else 'black')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation = 'vertical')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.savefig(os.path.join('proportions', title + '.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ec_color(ec_name):\n",
    "    color_hex = '#'\n",
    "    for x in np.random.randint(256, size = 3):\n",
    "        vhex = hex(x)[2:]\n",
    "        if len(vhex) == 1:\n",
    "            vhex = '0' + vhex\n",
    "        color_hex += vhex\n",
    "    return color_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ec_label(key):\n",
    "    final_label = ''\n",
    "    words = key.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word.endswith('s'):\n",
    "            word = word[:-1]\n",
    "        final_label += word\n",
    "        if i < len(words) - 1:\n",
    "            final_label += ' '\n",
    "    \n",
    "    words = final_label.split()\n",
    "    if len(words) > 1 and words[1] == '-':\n",
    "        final_label = words[-1]\n",
    "    \n",
    "    final_label = final_label.replace('atico', 'ático').replace('oide', 'óide').replace('icula', 'ícula') \n",
    "    final_label = final_label.capitalize()\n",
    "    if re.search('_[0-9]*$', final_label):\n",
    "        final_label = final_label[:final_label.rfind('_')]\n",
    "    return final_label\n",
    "\n",
    "def correct(element_name, is_ec = False):\n",
    "    if element_name == '�xido de Tit�nio':\n",
    "        return 'Óxido de Titânio'\n",
    "    if element_name == 'Zirc�o':\n",
    "        return 'Zircão'\n",
    "    return get_ec_label(element_name) if is_ec else element_name\n",
    "\n",
    "def unify_labels(include_qemscan, include_ec, data_dir, groups, from_nc, unified_labels_file, initial_labels = None):\n",
    "    pore_new_color_hex = '#636363'\n",
    "    \n",
    "    elements = {'Element': [], 'type': [], 'color_hex': []}\n",
    "    if from_nc:\n",
    "        for group in groups:\n",
    "            for depth in groups[group]:\n",
    "                nc_path = os.path.join(data_dir, group, gen_nc_file_name(group, depth))\n",
    "                print('Label unification: reading from', nc_path)\n",
    "                data = Dataset(nc_path, 'r')\n",
    "                \n",
    "                for key in data.variables.keys():\n",
    "                    if any(key.startswith(coord) for coord in ['c_', 'x_', 'y_', 'z_']):\n",
    "                        continue\n",
    "                    is_qemscan = ('QEMSCAN' in key) or (('Q' in key) and ('Transformed' in key))\n",
    "                    is_ec = all(light not in key for light in ['PP', 'PX']) \\\n",
    "                        and (key not in ['c', 'x', 'y', 'z']) and (not key.startswith('SOI'))\\\n",
    "                        and not is_qemscan\n",
    " \n",
    "                    if (include_qemscan and is_qemscan):\n",
    "                        segmented_data = data.variables[key]\n",
    "                        for color_info in segmented_data.labels[1:]:\n",
    "                            color_info = color_info.split(',')\n",
    "                            elements['Element'].append(correct(color_info[0]))\n",
    "                            elements['type'].append('qemscan')\n",
    "                            if color_info == pore_new_color_hex:\n",
    "                                raise Exception('Element' + color_info[0] + 'is represented by the color hex' + color_info[2] + \\\n",
    "                                                ', which would be used to replace pore\\'s zero color hex.')\n",
    "                            if color_info[2] == '#000000':\n",
    "                                color_info[2] = pore_new_color_hex\n",
    "                            elements['color_hex'].append(color_info[2])\n",
    "                            #elements['R'].append(int(color_info[2][1:3], 16))\n",
    "                            #elements['G'].append(int(color_info[2][3:5], 16))\n",
    "                            #elements['B'].append(int(color_info[2][5: ], 16))\n",
    "                \n",
    "                    elif (include_ec and is_ec):\n",
    "                        segmented_data = data.variables[key]\n",
    "                        \n",
    "                        ec_name = get_ec_label(key)\n",
    "                        if ec_name not in elements['Element']:\n",
    "                            elements['Element'].append(ec_name)\n",
    "                            elements['type'].append('ec')\n",
    "                            elements['color_hex'].append(get_ec_color(ec_name))  \n",
    "\n",
    "                data.close()\n",
    "    else:\n",
    "        elements['Element'].append('Poros')    \n",
    "        elements['color_hex'].append(pore_new_color_hex)    \n",
    "    \n",
    "    unified_labels = pd.DataFrame(elements)\n",
    "    unified_labels = unified_labels.drop_duplicates()\n",
    "        \n",
    "    unified_labels = unified_labels.sort_values(by = ['type', 'Element'])\n",
    "    \n",
    "    indexes = []\n",
    "    for label_type in unified_labels['type'].unique():\n",
    "        if initial_labels is None:\n",
    "            initial_labels = {}\n",
    "        \n",
    "        if label_type not in initial_labels:\n",
    "            initial_labels[label_type] = 1\n",
    "\n",
    "        start_index = initial_labels[label_type]\n",
    "        indexes += list(range(start_index, unified_labels[unified_labels['type'] == label_type].shape[0] + start_index))\n",
    "            \n",
    "    unified_labels.set_index([indexes], inplace = True)\n",
    "\n",
    "    print(unified_labels)\n",
    "    \n",
    "    assert not unified_labels['Element'].duplicated().any(),\\\n",
    "        'Element ' + unified_labels['Element'][unified_labels['Element'].duplicated()] + ' appears more than once.'\n",
    "    assert not unified_labels['color_hex'].duplicated().any(),\\\n",
    "        'Color ' + unified_labels['color_hex'][unified_labels['color_hex'].duplicated()] +  ' appears more than once.'\n",
    "    \n",
    "    unified_labels.to_csv(unified_labels_file)\n",
    "    \n",
    "    print('Labels unified successfully!')\n",
    "        \n",
    "def convert_labels_to_unified(segmented_data, unified_labels, element = 'all', is_ec = False, split_instances = False):\n",
    "    label = np.ma.getdata(segmented_data[0])\n",
    "    adapted_label = np.zeros(label.shape)\n",
    "    \n",
    "    if element == 'all':\n",
    "        for color_info in segmented_data.labels[1:]:\n",
    "            element, elem_label = color_info.split(',')[:2]\n",
    "\n",
    "            adapted_label[np.where(label == int(elem_label))] = \\\n",
    "                unified_labels[unified_labels['Element'] == correct(element, is_ec)].index\n",
    "    else:\n",
    "        ### bounding-box\n",
    "        #for color_info in segmented_data.labels[1:]:\n",
    "        #    _, elem_label = color_info.split(',')[:2]\n",
    "        #    \n",
    "        #    elem_loc = np.where(label == int(elem_label))\n",
    "        #    ymin, ymax = min(elem_loc[0]), max(elem_loc[0])\n",
    "        #    xmin, xmax = min(elem_loc[1]), max(elem_loc[1])\n",
    "        #    adapted_label[ymin:ymax+1, xmin:xmax+1] = \\\n",
    "        #        unified_labels[unified_labels['Element'] == correct(element, is_ec)].index\n",
    "        \n",
    "        ### default\n",
    "        if not split_instances:\n",
    "            adapted_label = np.squeeze(adapted_label)\n",
    "            \n",
    "            adapted_label[np.where(label != 0)] = \\\n",
    "                unified_labels[unified_labels['Element'] == correct(element, is_ec)].index\n",
    "        else:\n",
    "            return label\n",
    "        \n",
    "    return adapted_label\n",
    "\n",
    "\n",
    "def calculate_minerals_proportions(qemscan, unified_labels):\n",
    "    unified_minerals = unified_labels[unified_labels['type'] == 'qemscan']\n",
    "    qemscan_proportions = {\n",
    "        'Desconhecido': qemscan[qemscan == 0].size / qemscan.size\n",
    "    }\n",
    "    \n",
    "    for i, datarow in unified_minerals.iterrows():\n",
    "        qemscan_proportions[datarow['Element']] = qemscan[qemscan == i].size / qemscan.size\n",
    "    \n",
    "    return qemscan_proportions\n",
    "\n",
    "def calculate_general_proportions(proportions_list, weights = None):\n",
    "    proportions_table = pd.DataFrame(proportions_list)\n",
    "    if weights is None:\n",
    "        return proportions_table.mean()\n",
    "    \n",
    "    result = pd.Series(0, index = proportions_table.columns)\n",
    "    for weight, proportion in zip(weights, proportions_list):\n",
    "        result += weight * proportion\n",
    "    return result / np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_label means \"each segment belongs to the same class\"\n",
    "# Examples:\n",
    "# * QEMSCAN is a unique variable with 1 segment for each mineral phase. So, each segment belongs to a different class and single_label = False\n",
    "# * An EC class is full of segments, but them all belongs to such class. So, single_label = True \n",
    "def process_labels(data, variable_name, unified_labels, single_label = False, is_ec = False, split_instances = False):\n",
    "    segmented_data = data.variables[variable_name]\n",
    "    label = convert_labels_to_unified(segmented_data, unified_labels, element = variable_name if single_label else 'all',\n",
    "                                      is_ec = is_ec, split_instances = split_instances)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(group, depth, data_dir, from_nc, bg_thresh, show, unified_labels, missing_nodes_allowed = None, crop_soi_area = True, split_ec_instances = False):\n",
    "    if from_nc:\n",
    "        nc_path = os.path.join(data_dir, group, gen_nc_file_name(group, depth))\n",
    "        \n",
    "        print('Opening data file', nc_path)\n",
    "        data = Dataset(nc_path, 'r')\n",
    "\n",
    "        image   = None\n",
    "        qemscan = None\n",
    "        ec      = None\n",
    "        pp_variable_name  = None\n",
    "        px_variable_name  = None\n",
    "        qs_variable_name  = None\n",
    "        soi_variable_name = None\n",
    "        ec_variable_names = set()\n",
    "        for key in data.variables.keys():\n",
    "            if any(key.startswith(coord) for coord in ['c_', 'x_', 'y_', 'z_']):\n",
    "                continue\n",
    "            if 'PP' in key:\n",
    "                pp_variable_name = key\n",
    "            elif 'PX' in key:\n",
    "                px_variable_name = key\n",
    "            elif ('QEMSCAN' in key) or (('Q' in key) and ('Transformed' in key)):\n",
    "                qs_variable_name = key\n",
    "            elif key.startswith('SOI'):\n",
    "                soi_variable_name = key\n",
    "            elif key not in ['c', 'x', 'y', 'z']:\n",
    "                ec_variable_names.add(key)\n",
    " \n",
    "        has_pp      = pp_variable_name  is not None\n",
    "        has_px      = px_variable_name  is not None\n",
    "        has_qemscan = qs_variable_name  is not None\n",
    "        has_soi     = soi_variable_name is not None\n",
    "        has_ec      = len(ec_variable_names) > 0\n",
    "        int_has_pp      = int(has_pp)\n",
    "        int_has_px      = int(has_px)\n",
    "        int_has_qemscan = int(has_qemscan)\n",
    "        int_has_ec      = int(has_ec)\n",
    "        \n",
    "        for node, has_node in zip([has_pp, has_px, has_qemscan, has_ec], ['pp', 'px', 'qemscan', 'ec']):\n",
    "            assert has_node or node in missing_nodes_allowed,\\\n",
    "                os.path.basename(nc_path) + ' has no ' + node.upper() + ' node. Repair it or include \\'' + node + '\\' in missing_nodes_allowed.'\n",
    "    \n",
    "        # As variáveis são masked_array. A função np.getdata() obtém apenas os dados no formato numpy, sem máscara\n",
    "        if has_pp:\n",
    "            image = np.ma.getdata(data.variables[pp_variable_name][0])\n",
    "        \n",
    "        if has_px:\n",
    "            if image is not None:\n",
    "                image = np.concatenate(\n",
    "                    (\n",
    "                        image,\n",
    "                        np.ma.getdata(data.variables[px_variable_name][0])\n",
    "                    ),\n",
    "                    axis = 2\n",
    "                )\n",
    "            else:\n",
    "                image = np.ma.getdata(data.variables[px_variable_name][0])\n",
    "        \n",
    "        if has_qemscan:\n",
    "            qemscan = process_labels(data, qs_variable_name, unified_labels)\n",
    "                \n",
    "        if has_soi:\n",
    "            soi = np.ma.getdata(data.variables[soi_variable_name][0])\n",
    "        else:\n",
    "            soi = np.ones(image.shape[:2] if image is not None else qemscan.shape)\n",
    "    \n",
    "        if has_ec:\n",
    "            ec = None\n",
    "            ec_variable_names = list(ec_variable_names)\n",
    "            ec_variable_names.sort()\n",
    "            n_ec_classes = unified_labels[unified_labels['type'] == 'ec'].shape[0]#count()\n",
    "            for ec_label in ec_variable_names:\n",
    "                eseg = process_labels(data, ec_label, unified_labels, single_label = True, is_ec = True, split_instances = split_ec_instances)\n",
    "                if not split_ec_instances:\n",
    "                    if ec is None:\n",
    "                        ec = ec = np.zeros((*eseg.shape[:2],))\n",
    "                    ec[eseg != 0] = eseg[eseg != 0]\n",
    "                else:\n",
    "                    ec_index = unified_labels[unified_labels['Element'] == correct(ec_label, is_ec = True)].index[0] - 1\n",
    "                    if ec is None:\n",
    "                        ec = np.zeros((*eseg.shape[:2], n_ec_classes))\n",
    "                    ec[:, :, ec_index] = eseg\n",
    "    \n",
    "        data.close()\n",
    "    else:\n",
    "        arrays_paths = glob.glob(os.path.join(data_dir, group, depth, '*.nrrd'))\n",
    "        print('Opening pore data at depth', depth)\n",
    "        \n",
    "        for array_path in arrays_paths:\n",
    "            filename = os.path.basename(array_path)\n",
    "            if filename.startswith('BUZ'):\n",
    "                image = np.moveaxis(nrrd.read(array_path)[0], 0, 2)[:, :, :, 0]\n",
    "            elif filename.startswith('SOI'):\n",
    "                soi = nrrd.read(array_path)[0][:, :, 0]\n",
    "            elif filename.startswith('Seg') and 'LabelMap' not in filename:\n",
    "                label = (~(nrrd.read(array_path)[0] - 1).astype(bool)).astype(np.uint8)[:, :, 0]\n",
    "\n",
    "    channels_per_light = 3\n",
    "    has_image = has_pp or has_px\n",
    "    \n",
    "    mask = soi.astype(bool)\n",
    "\n",
    "    if show:\n",
    "        axes = plt.subplots(2, 1 + int_has_pp + int_has_px + int_has_qemscan + int_has_ec)[1]\n",
    "        col = 0\n",
    "        first_exib_channel = 0\n",
    "        \n",
    "        if has_pp:\n",
    "            imshow_mini(image[:, :, first_exib_channel:first_exib_channel+channels_per_light], axes[0][col], 'PP', unified_labels)\n",
    "            first_exib_channel += channels_per_light\n",
    "            col += 1\n",
    "        if has_px:\n",
    "            imshow_mini(image[:, :, first_exib_channel:first_exib_channel+channels_per_light], axes[0][col], 'PX', unified_labels)\n",
    "            col += 1\n",
    "        if has_qemscan: \n",
    "            imshow_mini(qemscan, axes[0][col], 'QEMSCAN', unified_labels, remap_colors = from_nc)\n",
    "            col += 1\n",
    "        if has_ec: \n",
    "            imshow_mini(ec, axes[0][col], 'E.C.', unified_labels, remap_colors = from_nc)\n",
    "            col += 1\n",
    "        imshow_mini(soi, axes[0][col], 'SOI', unified_labels, cmap = 'gray')\n",
    "\n",
    "    if crop_soi_area:\n",
    "        nonzero_rows, nonzero_cols = np.where(mask != 0)\n",
    "        row_min, row_max, col_min, col_max = \\\n",
    "            nonzero_rows.min(), nonzero_rows.max(), nonzero_cols.min(), nonzero_cols.max()\n",
    "\n",
    "        if has_image:\n",
    "            image[np.where(mask == 0)] = 0\n",
    "            image = image[row_min:row_max+1, col_min:col_max+1]\n",
    "        if has_qemscan:\n",
    "            qemscan[np.where(mask == 0)] = 0\n",
    "            qemscan = qemscan[row_min:row_max+1, col_min:col_max+1]\n",
    "        soi = soi[row_min:row_max+1, col_min:col_max+1]\n",
    "    \n",
    "    if show:\n",
    "        col = 0\n",
    "        first_exib_channel = 0\n",
    "        \n",
    "        if has_pp:\n",
    "            imshow_mini(image[:, :, first_exib_channel:first_exib_channel+channels_per_light], axes[1][col], 'useful area:\\nPP', unified_labels)\n",
    "            first_exib_channel += channels_per_light\n",
    "            col += 1\n",
    "        if has_px:\n",
    "            imshow_mini(image[:, :, first_exib_channel:first_exib_channel+channels_per_light], axes[1][col], 'useful area:\\nPX', unified_labels)\n",
    "            col += 1\n",
    "        if has_qemscan: \n",
    "            imshow_mini(qemscan, axes[1][col], 'useful area:\\nQEMSCAN', unified_labels, remap_colors = from_nc)\n",
    "            col += 1\n",
    "        if has_ec: \n",
    "            imshow_mini(ec, axes[1][col], 'useful area:\\nE.C.', unified_labels, remap_colors = from_nc)\n",
    "            col += 1\n",
    "        axes[1][col].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    output = []\n",
    "    for array in [image, qemscan, ec, soi]:\n",
    "        if array is not None:\n",
    "            array = array.astype(np.uint8 if array.max() <= 255 else np.uint16)\n",
    "        output.append(array)\n",
    "    \n",
    "    return tuple(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(image, output_dir, extension, index, channel_first, as_volume, final_size, is_segment, prefix = None, suffix = None,\n",
    "         compact_rgb = False):\n",
    "    orig_shape = image.shape\n",
    "    n_channels = image.shape[-1] if image.ndim == 3 else 1\n",
    "    \n",
    "    if channel_first:\n",
    "        if image.ndim == 2:\n",
    "            image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "        else:\n",
    "            image = np.rollaxis(image, image.ndim - 1)\n",
    "        \n",
    "    \n",
    "    if final_size is not None:\n",
    "        # if is_segment: interpolate by nearest neighbors (order 0); else: interpolate by smoothing (order 1)\n",
    "        image = sk_resize(image, (final_size, final_size), preserve_range = True, order = int(not is_segment)).astype(np.uint16)\n",
    "        \n",
    "    if n_channels == 3:\n",
    "        if compact_rgb:\n",
    "            image = image.view(dtype = [('R', 'u1'), ('G', 'u1'), ('B', 'u1')])\n",
    "        if as_volume:\n",
    "            image = image.reshape(*image.shape, 1)\n",
    "            \n",
    "    if index == 0 and orig_shape != image.shape:\n",
    "        print('** Shape transformed from', orig_shape, 'to', image.shape, '**')\n",
    "    \n",
    "    if prefix is None:\n",
    "        prefix = ''\n",
    "    if suffix is None:\n",
    "        suffix = ''\n",
    "    \n",
    "    output_path = os.path.join(output_dir, prefix + '{:04d}'.format(index) + suffix + '.' + extension)\n",
    "    if extension == 'nii.gz':\n",
    "        nib.save(nib.Nifti1Image(image, affine = None), output_path)\n",
    "    elif extension == 'tif':\n",
    "        tif.imwrite(output_path, image)\n",
    "    elif extension == 'png':\n",
    "        try:\n",
    "            cv2.imwrite(output_path, image if n_channels == 1 else cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "        except:\n",
    "            output_path = os.path.join(output_dir, prefix + '{:04d}'.format(index) + suffix + '.' + 'seg.nrrd')\n",
    "            header = None\n",
    "            if n_channels == 3:\n",
    "                channel_dim = 0 if channel_first else 2\n",
    "                header = {'kinds': image.ndim * ['domain']}\n",
    "                header['kinds'][channel_dim] = 'RGB-color'\n",
    "\n",
    "            nrrd.write(output_path, image, header = header)\n",
    "    else:\n",
    "        header = None\n",
    "        if n_channels == 3:\n",
    "            channel_dim = 0 if channel_first else 2\n",
    "            header = {'kinds': image.ndim * ['domain']}\n",
    "            header['kinds'][channel_dim] = 'RGB-color'\n",
    "            \n",
    "        nrrd.write(output_path, image, header = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_void_pixels(data, label):\n",
    "    print('Computing void coords...')\n",
    "    data_voids   = np.where((data == 0).all(axis = 2))\n",
    "    label_voids  = np.where(label == 0)\n",
    "    common_voids = np.where((data == 0).all(axis = 2) & (label == 0))\n",
    "    \n",
    "    print('Zipping void coords...')\n",
    "    data_voids   = list(zip(list(data_voids[0]), list(data_voids[1])))\n",
    "    label_voids  = list(zip(list(label_voids[0]), list(label_voids[1])))\n",
    "    common_voids = list(zip(list(common_voids[0]), list(common_voids[1])))\n",
    "    \n",
    "    #print('Removing duplicates...')\n",
    "    #data_voids  = [coord for coord in data_voids  if coord not in common_voids]\n",
    "    #label_voids = [coord for coord in label_voids if coord not in common_voids]\n",
    "\n",
    "    print('Creating images copies...')\n",
    "    marked_data = data.copy()\n",
    "    marked_label = label.copy()\n",
    "    print('Marking...')\n",
    "    for coords, color in zip([data_voids, label_voids, common_voids], [(255, 0, 0), (0, 255, 0), (255, 255, 0)]):\n",
    "        print(coords, color)\n",
    "        for i, coord in enumerate(coords):\n",
    "            print('\\t', 100*(i+1)/len(coords), '%')\n",
    "            marked_data  = cv2.circle(marked_data,  coord, 1000, color, 3)\n",
    "            marked_label = cv2.circle(marked_label, coord, 1000, color, 3)\n",
    "    \n",
    "    ax = plt.subplots(1, 2)[1]\n",
    "    plt.suptitle('Red: data voids\\nGreen: label voids\\nYellow: common voids')\n",
    "    imshow_mini(marked_data[:, :, :3],  ax[0], '')\n",
    "    imshow_mini(marked_label,           ax[1], '')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52e18a-b328-4706-854e-15eadfc27000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some instances appear as one main island and some residual islands around. Getting only the greatest because\n",
    "# otherwise each island would be written in YOLO format as a different instance.\n",
    "def get_greatest_contour(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) == 1:\n",
    "        return contours[0]\n",
    "    max_size = 0\n",
    "    contour = None\n",
    "    for c in contours:\n",
    "        if c.shape[0] > max_size:\n",
    "            max_size = c.shape[0]\n",
    "            contour = c\n",
    "    return contour\n",
    "\n",
    "def save_anot_yolo_format(chunk, output_dir, index, prefix = None, suffix = None, save_bbox = False, save_seg = False):\n",
    "    if prefix is None:\n",
    "        prefix = ''\n",
    "    if suffix is None:\n",
    "        suffix = ''\n",
    "    \n",
    "    out_filename = prefix + '{:04d}'.format(index) + suffix + '.' + 'txt'\n",
    "    bbox_dir = os.path.join(os.path.dirname(output_dir), 'ec_yolo_bboxes')\n",
    "    seg_dir  = os.path.join(os.path.dirname(output_dir), 'ec_yolo_seg')\n",
    "    output_path = {\n",
    "        'bbox': os.path.join(bbox_dir, out_filename),\n",
    "        'seg' : os.path.join(seg_dir,  out_filename)\n",
    "    }\n",
    "    \n",
    "    if save_bbox:\n",
    "        os.makedirs(bbox_dir, exist_ok = True)\n",
    "        bbox_file = open(output_path['bbox'], 'w')\n",
    "    if save_seg:\n",
    "        os.makedirs(seg_dir,  exist_ok = True)\n",
    "        seg_file = open(output_path['seg'], 'w')\n",
    "\n",
    "    for i in range(chunk.shape[-1]):\n",
    "        # Find contours in the mask image\n",
    "        class_masks = chunk[:,:,i]#.astype(np.uint8)\n",
    "        instances = np.unique(class_masks)\n",
    "        for instance in tqdm(instances):\n",
    "            if instance == 0:\n",
    "                continue\n",
    "\n",
    "            mask = np.where(class_masks == instance, 1, 0).astype(np.uint8)\n",
    "            \n",
    "            # Some instances appear as one main island and some residual islands around. Getting only the greatest because\n",
    "            # otherwise each island would be written in YOLO format as a different instance.\n",
    "            contour = get_greatest_contour(mask)\n",
    "\n",
    "            # Write bounding boxes to file in YOLO format\n",
    "            if save_bbox:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                bbox_file.write('{:d} {:.6f} {:.6f} {:.6f} {:.6f}\\n'.format(i, (x+w/2)/chunk.shape[1], (y+h/2)/chunk.shape[0], w/chunk.shape[1], h/chunk.shape[0]))\n",
    "            if save_seg:\n",
    "                segment_yolo = (np.squeeze(contour)/chunk.shape[:2][::-1]).ravel().astype('str')\n",
    "                seg_file.write('{:d} '.format(i)+' '.join(segment_yolo)+'\\n')\n",
    "    \n",
    "    if save_bbox:\n",
    "        bbox_file.close()\n",
    "    if save_seg:\n",
    "        seg_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(groups, data_dir, from_nc = True, do_qemscan_unification = False, do_ec_unification = False,\n",
    "                unified_labels_file = 'unified_labels.csv', initial_labels = None, ds_image_size = 32,\n",
    "                extension = 'nii.gz', channel_first = False, preserve_channels = False, as_volume = False, show = False,\n",
    "                save_nodes = None, calc_props = True, bg_thresh = 10, shrank = False, max_zero_rate_thresh = 1,\n",
    "                missing_nodes_allowed = None, final_size = None, single_output_dir = False, save_randomized = False,\n",
    "               compact_rgb = False, crop_soi_area = True, split_ec_instances = False, yolo=False, yolo_seg=False, occlusion_percentage=None):\n",
    "    accepted_extensions = ['nii.gz', 'tif', 'png', 'seg.nrrd', 'nrrd']\n",
    "    accepted_nodes = ['pp', 'px', 'qemscan', 'ec']\n",
    "    \n",
    "    #ds_image_size in format (x, y) (i.e., index 0 is x)\n",
    "    \n",
    "    save = save_nodes is not None and len(save_nodes) > 0\n",
    "    full_size = ds_image_size is None\n",
    "    if save:\n",
    "        if type(extension) == str:\n",
    "            extension = (extension,) * len(save_nodes)\n",
    "        assert all(e in accepted_extensions for e in extension),   'Supported formats: ' + str(accepted_extensions)\n",
    "        assert all(node in accepted_nodes for node in save_nodes), 'Compatible nodes: '  + str(accepted_nodes)\n",
    "    assert do_qemscan_unification or do_ec_unification or show or save or calc_props, 'Nothing to do.'\n",
    "    assert full_size or type(ds_image_size) == int or len(ds_image_size) == 2\n",
    "    assert not show or not split_ec_instances, 'For now, splitted ECs cannot be exhibited. Use split_ec_instances = False when using show = True.'\n",
    "    assert occlusion_percentage is None or type(occlusion_percentage) in [int, float, list] or type(occlusion_percentage) \n",
    "    \n",
    "    ds_path = os.path.join(data_dir, 'generated')\n",
    "    os.makedirs(ds_path, exist_ok = True)\n",
    "    \n",
    "    if do_qemscan_unification or do_ec_unification:\n",
    "        unify_labels(do_qemscan_unification, do_ec_unification, data_dir, groups, from_nc, unified_labels_file, initial_labels)\n",
    "    unified_labels = pd.read_csv(unified_labels_file, index_col = 0)\n",
    "    \n",
    "    if occlusion_percentage is not None:\n",
    "        n_ec_classes = unified_labels[unified_labels['type'] == 'ec'].shape[0]\n",
    "        if type(occlusion_percentage) in [int, float]:\n",
    "            occlusion_percentage = n_ec_classes * [occlusion_percentage]\n",
    "        assert len(occlusion_percentage) == n_ec_classes, f'occlusion_percentage must be None, a single value or a list containing ' + \\\n",
    "            f'one value per EC class. Found {n_ec_classes} EC classes but {len(occlusion_percentage)} occlusion percentages.'\n",
    "    \n",
    "    dataset_proportions = []\n",
    "    proportion_weights = []\n",
    "    \n",
    "    if type(ds_image_size) == int:\n",
    "        ds_image_size = (ds_image_size, ds_image_size)\n",
    "    \n",
    "    size_infix = str(ds_image_size[0]) + 'x' + str(ds_image_size[1]) if not full_size else 'WxH'\n",
    "    final_size_suffix = ('_as_' + str(final_size) + 'x' + str(final_size)) if final_size is not None else ''\n",
    "    channel_suffix = '_cf' if channel_first else ''\n",
    "    channel_suffix += '_ch' if preserve_channels else ''\n",
    "    vol_suffix = '_vol' if as_volume else ''\n",
    "    shrink_suffix = '_shrank' if shrank else ''\n",
    "    datetime_suffix = datetime.datetime.now().strftime(\"_%d.%m.%Y-%H.%M.%S\") if single_output_dir else ''\n",
    "    \n",
    "    delete_output_dir = save\n",
    "    for group in groups:\n",
    "        for depth in groups[group]:\n",
    "            data, qemscan, ec, soi = load_and_preprocess(group, depth, data_dir, from_nc, bg_thresh, show, unified_labels,\n",
    "                                                         missing_nodes_allowed, crop_soi_area, split_ec_instances)\n",
    "            \n",
    "            if not save and not calc_props:\n",
    "                continue\n",
    "\n",
    "            h, w = soi.shape\n",
    "            if full_size:\n",
    "                ds_image_size = (w, h)\n",
    "                \n",
    "            if not single_output_dir:\n",
    "                general_output_dir = os.path.join(ds_path, group, depth, size_infix \\\n",
    "                                              + final_size_suffix + '_' + str(extension) + channel_suffix + vol_suffix + shrink_suffix)\n",
    "            else:\n",
    "                general_output_dir = os.path.join(ds_path, size_infix \\\n",
    "                                              + final_size_suffix + '_' + str(extension) + channel_suffix + vol_suffix + shrink_suffix \\\n",
    "                                              + datetime_suffix)\n",
    "            \n",
    "            if delete_output_dir:\n",
    "                shutil.rmtree(general_output_dir, ignore_errors = True)\n",
    "                delete_output_dir = not single_output_dir\n",
    "\n",
    "            minerals_proportions = []\n",
    "            file_prefixes = {}\n",
    "            file_suffixes = {}\n",
    "            view = {}\n",
    "            random_prefixes = np.arange(100000) if save_randomized else None\n",
    "            \n",
    "            chunk_indexes = {\n",
    "                'y': np.arange(0, h - ds_image_size[1], ds_image_size[1]) if not full_size else [0],\n",
    "                'x': np.arange(0, w - ds_image_size[0], ds_image_size[0]) if not full_size else [0],\n",
    "            }\n",
    "            n_chunks_x = (w//ds_image_size[0])\n",
    "            n_chunks_y = (h//ds_image_size[1])\n",
    "            n_chunks = n_chunks_x * n_chunks_y\n",
    "            crop_w = ds_image_size[0] * n_chunks_x\n",
    "            crop_h = ds_image_size[1] * n_chunks_y\n",
    "            \n",
    "            soi = soi[(h-crop_h)//2 : (h+crop_h)//2, (w-crop_w)//2 : (w+crop_w)//2]\n",
    "            \n",
    "            sets = []\n",
    "            i_ext = 0\n",
    "            print('*** set_type: central shape [discarding boards not suitable in image.shape/ds_image_size] --> (N, H, W, C[, D]) ***')\n",
    "            for set_type, image in [('data', data), ('qemscan', qemscan), ('ec', ec)]:\n",
    "                if image is None or (set_type != 'data' and set_type not in save_nodes) or \\\n",
    "                    (set_type == 'data' and 'pp' not in save_nodes and 'px' not in save_nodes):\n",
    "                    continue\n",
    "\n",
    "                output_dir = os.path.join(general_output_dir, set_type)\n",
    "                os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "                image = image[(h-crop_h)//2 : (h+crop_h)//2, (w-crop_w)//2 : (w+crop_w)//2]\n",
    "                \n",
    "                if show:\n",
    "                    view[set_type] = image.copy()\n",
    "                print(set_type + ':', image.shape, end = ' --> ')\n",
    "\n",
    "                window_shape = (ds_image_size[1], ds_image_size[0])\n",
    "                if image.ndim == 3:\n",
    "                    window_shape += (image.shape[-1],)\n",
    "\n",
    "                print((n_chunks,) + window_shape)\n",
    "                \n",
    "                sets.append((set_type, image, output_dir, extension[i_ext]))\n",
    "                i_ext += 1\n",
    "\n",
    "            i_chunk = 0\n",
    "            discarded = 0\n",
    "            for yi in chunk_indexes['y']:\n",
    "                for xi in chunk_indexes['x']:\n",
    "                    i_chunk += 1\n",
    "                    if n_chunks >= 10 and (i_chunk % (n_chunks//10)) == 0:\n",
    "                        print(i_chunk, '/', n_chunks, '(' + str(round(100*i_chunk/n_chunks)) + '%)')\n",
    "\n",
    "                    chunk_soi = soi[yi : yi + ds_image_size[1], xi : xi + ds_image_size[0]]\n",
    "                    zero_rate = 1 - np.count_nonzero(chunk_soi)/chunk_soi.size\n",
    "\n",
    "                    if zero_rate <= max_zero_rate_thresh:\n",
    "                        if save:\n",
    "                            prefix = None\n",
    "                            suffix  = None\n",
    "                            if save_randomized:\n",
    "                                prefix = np.random.choice(random_prefixes)\n",
    "                                random_prefixes = np.delete(random_prefixes, np.where(random_prefixes == prefix))\n",
    "                                prefix = str(prefix) + '.'\n",
    "                            if single_output_dir:\n",
    "                                suffix = '_' + group + '_' + str(depth)\n",
    "                            \n",
    "                            for set_type, image, output_dir, set_extension in sets:\n",
    "                                chunk = image[yi : yi + ds_image_size[1], xi : xi + ds_image_size[0]]\n",
    "                                \n",
    "                                if occlusion_percentage and set_type == 'ec':\n",
    "                                    for i in range(image.shape[-1]):                                        \n",
    "                                        border_pixels = np.concatenate((chunk[0,                   0 : ds_image_size[0]-1, i], \n",
    "                                                                        chunk[ds_image_size[1]-1,     0 : ds_image_size[0]-1, i],\n",
    "                                                                        chunk[0 : ds_image_size[1]-1, 0,                   i],\n",
    "                                                                        chunk[0 : ds_image_size[1]-1, ds_image_size[0]-1,     i]))\n",
    "                                        cropped_elements = np.unique(border_pixels)[1:]\n",
    "                                        \n",
    "                                        for j in cropped_elements:\n",
    "                                            partial = (chunk[:,:,i]==j).sum()\n",
    "                                            total = (image[:,:,i]==j).sum()\n",
    "                                            if partial/total < occlusion_percentage[i]:\n",
    "                                                chunk[chunk[:,:,i]==j] = 0\n",
    "                                        \n",
    "                                        # for j in cropped_elements:\n",
    "                                        #     chunk[:,:,i][chunk[:,:,i]==j] = 0\n",
    "\n",
    "                                if set_type == 'qemscan' and calc_props:\n",
    "                                    minerals_proportions.append(calculate_minerals_proportions(chunk, unified_labels))\n",
    "                                \n",
    "                                if set_type == 'data' and chunk.shape[-1] > 3:\n",
    "                                    if 'pp' not in save_nodes:\n",
    "                                        chunk = chunk[:, :, 3:]\n",
    "                                    if 'px' not in save_nodes:\n",
    "                                        chunk = chunk[:, :, :3]\n",
    "                                \n",
    "                                if set_type == 'ec':\n",
    "                                    if yolo or yolo_seg:\n",
    "                                        save_anot_yolo_format(chunk, output_dir, i_chunk, prefix = prefix, suffix = suffix,\n",
    "                                                             save_bbox = yolo, save_seg = yolo_seg)\n",
    "\n",
    "                                write(chunk, output_dir, set_extension, i_chunk, channel_first, as_volume, final_size,\n",
    "                                      is_segment = (set_type != 'data'), prefix = prefix, suffix = suffix,\n",
    "                                      compact_rgb = compact_rgb)\n",
    "\n",
    "                                if show:\n",
    "                                    view[set_type][yi : yi + ds_image_size[1], xi : xi + ds_image_size[0]] = \\\n",
    "                                        (view[set_type][yi : yi + ds_image_size[1], xi : xi + ds_image_size[0]] + view[set_type].max() + 1)//2\n",
    "                    \n",
    "                    else:\n",
    "                        discarded += 1\n",
    "    \n",
    "            n_valid = n_chunks - discarded\n",
    "            print('Done.', n_valid, 'valid,', discarded, 'discarded (background).')\n",
    "            \n",
    "            if show:\n",
    "                n_cols = len(view.keys())\n",
    "                ax = plt.subplots(1, n_cols)[1]\n",
    "                for i, set_type in enumerate(view.keys()):\n",
    "                    if set_type == 'data':\n",
    "                        view[set_type] = view[set_type][:, :, :3]\n",
    "                    imshow_mini(view[set_type], ax[i] if n_cols > 1 else ax, '', unified_labels)\n",
    "                plt.show()\n",
    "            \n",
    "            if calc_props:\n",
    "                group_proportions = calculate_general_proportions(minerals_proportions)\n",
    "                proportion_weights.append(n_valid)\n",
    "\n",
    "                plot_proportions(group_proportions, unified_labels, gen_nc_file_name(group, depth))\n",
    "                dataset_proportions.append(group_proportions)\n",
    "    \n",
    "    if calc_props:\n",
    "        plot_proportions(calculate_general_proportions(dataset_proportions, weights = proportion_weights), unified_labels, 'DATASET PROPORTIONS ' + list(groups.keys())[0] + '-' + list(groups.keys())[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'A': ['5228.45', '5230.5', '5232.1', '5235.5', '5242.95', '5246.95', '5247.7'],\n",
    "    'B': ['5129.8', '5163.8', '5187.6', '5208', '5218.2'],\n",
    "    'C': ['5565', '5705', '5732.5', '5758.5', '5766.4', '5813.2', '5823.3', '5838.2'],\n",
    "    'D': ['6148.6', '6150', '6166', '6178.8', '6189', '6199.5', '6202', '6212', '6224', '6234', '6277', '6293.5', '6295'] # por engano, 6212 não foi incluída antes (quando o modelo principal foi treinado) \\ \n",
    "        + ['6164.5'], # o PP tem resolução baixa e o QEMSCAN está errado. Usar se precisar do PX apenas\n",
    "    'F': ['4938.3', '4941.8'] + ['4964.45'], # o último não tem QEMSCAN válido\n",
    "    'G': ['5300.5', '5304'] + ['5268.5'], # o último não tem QEMSCAN válido\n",
    "    'H': ['5615.8', '5629.45', '5630.8'],\n",
    "    'I': ['5573.7', '5595.1', '5646.9'],\n",
    "    'K': ['5427', '5368'],\n",
    "    'L': ['5350.1', '5439.05', '5486.75'],\n",
    "    'M': ['5229.75', '5235.75'] + ['5168.05', '5168.05t', '5219.38', '5236.95'], # os últimos não têm QEMSCAN válido; todas as imagens exceto a 5229.75 pertencem ao lote 2\n",
    "    'P': ['5389.75'],\n",
    "    'Q': ['5503.25', '5505.05'],\n",
    "    'R': ['5182'],\n",
    "    \n",
    "    # new data\n",
    "    'AR': ['6374.95', '6375.65', '6376.00', '6376.65', '6376.95', '6378.05', '6379.05', '6379.80', '6380.15', '6380.45', '6380.80', '6381.90'],\n",
    "    'AS': ['5672.00', '5675.70'],\n",
    "    'FL': ['5400.25', '5401.00', '5404.65'], # '5400.55' tem resolução baixa\n",
    "    'LB': ['5472.20', '5477.70', '5481.65'],\n",
    "    'MR': ['5561.45'], # não tem QEMSCAN válido\n",
    "    'SA': ['6292.50', '6312.00'],\n",
    "    'SC': ['6328.00', '6328.00t', '6340.50', '6340.50t', '6342.20', '6342.20t', '6344.90', '6344.90t', '6346.60', '6346.60t', '6353.00', '6353.00t', '6355.00', '6355.00t', '6363.00', '6363.00t', '6364.50', '6364.50t', '6374.00t', '6390.00', '6390.00t', '6398.50', '6398.50t'],\n",
    "    'SL': ['5174.50'],\n",
    "    'YB': ['4822.00', '4846.80'],\n",
    "    \n",
    "    #'Siliciclastics': ['01', '02', '03', '04', '05', '06', '07']\n",
    "    \n",
    "    # Bug: 5607.35 (no SOI), 5609.20 (no SOI), 5608.85 (no SOI), 5608.60 (no SOI), 5609.45 (no SOI)\n",
    "    #'Processed_Poro': ['5611.80', '5769.20', '5623.10', '5765.50', '5631.55', '5628.25', '5610.65', '5617.05', '5662.30', '5795.05', '5603.45', '5623.65', '5749.30', '5790.00', '5627.25', '5720.40', '5621.05', '5604.00', '5759.00', '5612.10', '5643.60', '5629.90', '5711.10', '5610.45', '5631.10', '5811.50', '5804.70', '5607.95', '5881.20', '5636.40', '5690.00', '5862.00', '5634.55', '5603.10', '5637.45', '5844.80', '5651.10', '5684.20', '5780.15', '5851.10', '5613.20', '5622.05', '5613.50', '5633.80', '5707.30', '5616.15', '5611.05', '5666.40', '5635.50', '5620.15', '5705.10', '5602.45', '5634.90', '5632.30', '5871.00', '5632.00', '5636.65', '5627.95', '5714.40', '5832.70', '5610.35', '5726.30', '5790.65', '5621.75', '5612.45', '5619.00', '5800.05', '5739.50', '5639.30', '5602.05', '5716.70', '5775.25', '5802.00', '5754.00', '5618.35', '5785.15', '5614.55', '5632.95', '5699.50', '5822.10', '5635.75', '5607.35', '5609.20', '5608.85', '5608.60', '5609.45']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'A': ['5230.5'],\n",
    "    'B': ['5218.2'],\n",
    "    'C': ['5565', '5705'],\n",
    "    'D': ['6166'] # por engano, 6212 não foi incluída antes (quando o modelo principal foi treinado) \\ \n",
    "        + ['6164.5'], # o PP tem resolução baixa e o QEMSCAN está errado. Usar se precisar do PX apenas\n",
    "    'F': ['4941.8'], # o último não tem QEMSCAN válido\n",
    "    'G': ['5268.5'], # o último não tem QEMSCAN válido\n",
    "    'H': ['5630.8'],\n",
    "    'I': ['5573.7', '5595.1', '5646.9'],\n",
    "    'K': ['5427', '5368'],\n",
    "    'L': ['5350.1', '5439.05', '5486.75'],\n",
    "    'M': ['5229.75'], # os últimos não têm QEMSCAN válido; todas as imagens exceto a 5229.75 pertencem ao lote 2\n",
    "    'Q': ['5503.25'],\n",
    "    \n",
    "    # new data\n",
    "    'SA': ['6312.00'],\n",
    "    'SC': ['6328.00t', '6340.50t', '6342.20t', '6344.90t', '6346.60', '6346.60t', '6353.00', '6353.00t'],\n",
    "    \n",
    "    #'Siliciclastics': ['01', '02', '03', '04', '05', '06', '07']\n",
    "    \n",
    "    # Bug: 5607.35 (no SOI), 5609.20 (no SOI), 5608.85 (no SOI), 5608.60 (no SOI), 5609.45 (no SOI)\n",
    "    #'Processed_Poro': ['5611.80', '5769.20', '5623.10', '5765.50', '5631.55', '5628.25', '5610.65', '5617.05', '5662.30', '5795.05', '5603.45', '5623.65', '5749.30', '5790.00', '5627.25', '5720.40', '5621.05', '5604.00', '5759.00', '5612.10', '5643.60', '5629.90', '5711.10', '5610.45', '5631.10', '5811.50', '5804.70', '5607.95', '5881.20', '5636.40', '5690.00', '5862.00', '5634.55', '5603.10', '5637.45', '5844.80', '5651.10', '5684.20', '5780.15', '5851.10', '5613.20', '5622.05', '5613.50', '5633.80', '5707.30', '5616.15', '5611.05', '5666.40', '5635.50', '5620.15', '5705.10', '5602.45', '5634.90', '5632.30', '5871.00', '5632.00', '5636.65', '5627.95', '5714.40', '5832.70', '5610.35', '5726.30', '5790.65', '5621.75', '5612.45', '5619.00', '5800.05', '5739.50', '5639.30', '5602.05', '5716.70', '5775.25', '5802.00', '5754.00', '5618.35', '5785.15', '5614.55', '5632.95', '5699.50', '5822.10', '5635.75', '5607.35', '5609.20', '5608.85', '5608.60', '5609.45']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'A': ['5230.5'] + ['5228.45', '5232.1', '5246.95'],\n",
    "    'B': ['5129.8', '5163.8', '5187.6', '5208', '5218.2'],\n",
    "    'C': ['5565', '5705', '5732.5', '5758.5', '5766.4', '5813.2', '5823.3', '5838.2'],\n",
    "    'D': ['6150', '6166', '6178.8', '6199.5', '6202', '6212', '6224', '6234', '6277', '6293.5', '6295'] # por engano, 6212 não foi incluída antes (quando o modelo principal foi treinado) \\ \n",
    "        + ['6164.5'] + ['6189'],\n",
    "    'F': ['4941.8'] + ['4938.3', '4964.45'], # o último não tem QEMSCAN válido\n",
    "    'G': ['5268.5'] + ['5300.5', '5304.00'], # o último não tem QEMSCAN válido\n",
    "    'H': ['5615.8', '5629.45', '5630.8'],\n",
    "    'I': ['5573.7', '5595.1', '5646.9'],\n",
    "    'K': ['5427', '5368'],\n",
    "    'L': ['5350.1', '5439.05', '5486.75'],\n",
    "    'M': ['5229.75'] + ['5235.75', '5236.95'], # os últimos não têm QEMSCAN válido; todas as imagens exceto a 5229.75 pertencem ao lote 2\n",
    "    'Q': ['5503.25'],\n",
    "    \n",
    "    # new data\n",
    "    'AS': ['5672.00', '5675.70'],\n",
    "    'SA': ['6312.00'] + ['6292.50'],\n",
    "    'SC': ['6328.00t', '6340.50t', '6342.20t', '6344.90t', '6346.60t', '6353.00t'], # + ['6346.60t', '6353.00t']\n",
    "    \n",
    "    'AR': ['6376.65'],\n",
    "    'FL': ['5400.25', '5401.00', '5404.65'],\n",
    "    'LB': ['5472.20', '5477.70', '5481.65'],\n",
    "    'SL': ['5174.50'],\n",
    "    'YB': ['4822.00', '4846.80']\n",
    "    \n",
    "    #'Siliciclastics': ['01', '02', '03', '04', '05', '06', '07']\n",
    "    \n",
    "    # Bug: 5607.35 (no SOI), 5609.20 (no SOI), 5608.85 (no SOI), 5608.60 (no SOI), 5609.45 (no SOI)\n",
    "    #'Processed_Poro': ['5611.80', '5769.20', '5623.10', '5765.50', '5631.55', '5628.25', '5610.65', '5617.05', '5662.30', '5795.05', '5603.45', '5623.65', '5749.30', '5790.00', '5627.25', '5720.40', '5621.05', '5604.00', '5759.00', '5612.10', '5643.60', '5629.90', '5711.10', '5610.45', '5631.10', '5811.50', '5804.70', '5607.95', '5881.20', '5636.40', '5690.00', '5862.00', '5634.55', '5603.10', '5637.45', '5844.80', '5651.10', '5684.20', '5780.15', '5851.10', '5613.20', '5622.05', '5613.50', '5633.80', '5707.30', '5616.15', '5611.05', '5666.40', '5635.50', '5620.15', '5705.10', '5602.45', '5634.90', '5632.30', '5871.00', '5632.00', '5636.65', '5627.95', '5714.40', '5832.70', '5610.35', '5726.30', '5790.65', '5621.75', '5612.45', '5619.00', '5800.05', '5739.50', '5639.30', '5602.05', '5716.70', '5775.25', '5802.00', '5754.00', '5618.35', '5785.15', '5614.55', '5632.95', '5699.50', '5822.10', '5635.75', '5607.35', '5609.20', '5608.85', '5608.60', '5609.45']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f41d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = {\n",
    "#     'Siliciclastics': [f'numero_{i}' for i in range(5, 25, 2)] + ['01', '02', '03', '04', '05', '06', '07'] # numero_1 e numero_3 não têm QEMSCAN\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1effc9",
   "metadata": {},
   "source": [
    "groups = {\n",
    "    'D': ['6189'],\n",
    "    'A': ['5228.45', '5232.1', '5246.95'],\n",
    "    'AR': ['6376.65'],\n",
    "    'F': ['4938.3', '4964.45'],\n",
    "    'FL': ['5400.25', '5401.00', '5404.65'],\n",
    "    'G': ['5300.5', '5304.00'],\n",
    "    'LB': ['5472.20', '5477.70', '5481.65'],\n",
    "    'M': ['5235.75', '5236.95'],\n",
    "    #'Q': ['5505.05'],\n",
    "    'SA': ['6292.50'],\n",
    "    'SL': ['5174.50'],\n",
    "    'YB': ['4822.00', '4846.80']\n",
    "}\n",
    "sum = 0\n",
    "for key in groups:\n",
    "    sum += len(groups[key])\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'qemscan'\n",
    "dataset_dir = None\n",
    "\n",
    "if project == 'qemscan':\n",
    "    dataset_dir = 'D:\\\\Annotated' # os.path.join(os.sep, 'petrobr', 'parceirosbr', 'smartseg', 'datasets', 'qemscan')\n",
    "    from_nc = True\n",
    "elif project == 'poreseg':\n",
    "    dataset_dir = os.path.join(os.sep, 'petrobr', 'parceirosbr', 'smartseg', 'datasets', 'poreseg')\n",
    "    from_nc = False\n",
    "elif project == 'elementos_construtores':\n",
    "    dataset_dir = os.path.join(os.sep, 'petrobr', 'parceirosbr', 'smartseg', 'datasets', 'elementos_construtores')\n",
    "    from_nc = True\n",
    "\n",
    "# ATENÇÃO: O arquivo 'monailabel_labels.csv' tem o índice dos minerais iniciado em 50. Isso se deve ao fato de que o app testado\n",
    "# tinha 50 classes (com as excedentes consideradas para a feature de adição de novas classes dinamicamente). Futuramente,\n",
    "# considerar inserir em código o índice inicial.\n",
    "\n",
    "unified_labels_file = os.path.join(dataset_dir, 'labels.csv') #os.path.join(dataset_dir, 'unified_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72145c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@groups (dict(str, list(str))): dicionário em que as chaves descrevem os grupos (e.g. poços) de imagens a partir das quais o\n",
    "dataset será gerado e os valores são listas de imagens contidas em cada grupo. As imagens de cada grupo devem estar em um\n",
    "diretório com o nome do grupo e devem ser nomeadas conforme consta nas listas;\n",
    "\n",
    "@data_dir (str): diretório contendo os dados descritos em @groups;\n",
    "\n",
    "@from_nc (bool): Default: True; Booleano que indica se as imagens descritas em @groups têm o formato .nc. Caso falso,\n",
    "espera-se que se apresentem em formato .nrrd, em que cada nó (lâmina, segmentação, SOI, etc.) seja um arquivo distinto;\n",
    "\n",
    "@do_qemscan_unification (bool): Default: False; Caso verdadeiro, percorre o dataset extraindo todas as ocorrências distintas de\n",
    "minerais, atribuindo um rótulo numérico único para cada e salvando a informação no arquivo descrito em @unified_labels_file.\n",
    "Visa mitigar o fato de que o mesmo mineral consta com diferentes rótulos em diferentes imagens;\n",
    "\n",
    "@do_ec_unification (bool): Default: False; Similar ao @do_qemscan_unification, mas referente a elementos construtores ao invés\n",
    "de minerais;\n",
    "\n",
    "@unified_labels_file (str): Default: 'unified_labels.csv'; Arquivo no qual será registrada a unificação de rótulos descrita em\n",
    "@do_qemscan_unification e @do_ec_unification. Será usado na geração do dataset. Cria o arquivo, caso não exista;\n",
    "\n",
    "@sequential_label_indexes (bool): Default: False; Caso verdadeiro e @do_qemscan_unification e @do_ec_unification sejam\n",
    "verdadeiros, os elementos construtores e minerais são listados em @unified_labels_file com índices sequenciais, a partir de 1.\n",
    "Caso contrário, cada um dos tipos (elementos construtores / minerais) tem a própria enumeração, iniciada em 1;\n",
    "\n",
    "@ds_image_size (int): Default: 32; tamanho lateral dos recortes;\n",
    "\n",
    "@extension (str): Default: 'nii.gz'. Extensão dos arquivos contendo os recortes;\n",
    "\n",
    "@channel_first (bool): Default: False; Os recortes são salvos no formato CHW(D), caso verdadeiro, ou HWC(D), caso contrário;\n",
    "\n",
    "@preserve_channels: [deprectated]\n",
    "\n",
    "@as_volume (bool): Default: False; Caso verdadeiro, adiciona uma quarta dimensão ao recorte, representando profundidade 1;\n",
    "\n",
    "@show (bool): Default: False; Caso verdadeiro, exibe os nós PP, PX, rótulos (QEMSCAN e elementos construtores) e SOI da imagem,\n",
    "bem como sua área útil ao considerar o SOI como máscara;\n",
    "\n",
    "@save_nodes (list(str)): Default: None; Lista dos nós que serão incluídos nos recortes salvos. Suporta:\n",
    "    'pp';\n",
    "    'px';\n",
    "    'qemscan';\n",
    "    'ec' [elementos construtores];\n",
    "    [] ou None, caso não seja necessário salvar (indicado em casos de visualização (@show = True));\n",
    "\n",
    "@calc_props (bool): Default: True; Caso verdadeiro, calcula e exibe as proporções de cada fase mineral na área útil de cada\n",
    "imagem e, por fim, no dataset completo;\n",
    "\n",
    "@bg_tresh (int): [deprecated]\n",
    "\n",
    "@shrank (bool): Default: False; adiciona o sufixo '_shrank' nos diretórios gerados para o dataset final, para identificação\n",
    "caso se esteja trabalhando com imagens com o efeito shrink ativado;\n",
    "\n",
    "@max_zero_rate_thresh (float): Default: 1; porporção (0.0 - 1.0) de área não-útil aceitável para que o recorte seja salvo;\n",
    "\n",
    "** Parâmetros úteis para o projeto elementos_construtores com MONAI Label:\n",
    "\n",
    "@missing_nodes_allowed (bool): Default: False; Caso verdadeiro, deixa de ser obrigatório que as imagens tenham os nós\n",
    "especificados. Útil para construção de um dataset a ser rotulado. Suporta a nomenclatura de nós adotada em @save_nodes;\n",
    "\n",
    "@final_size (int): Default: None; Se especificado, as laterais dos recortes serão redimensionadas para este valor antes que\n",
    "ele seja salvo;\n",
    "\n",
    "@single_output_dir (bool): Default: False; Caso verdadeiro, salva todos os recortes em um mesmo diretório. Caso contrário,\n",
    "salva-os separados por grupo (vide @groups);\n",
    "\n",
    "@save_randomized (bool): Default: False; Caso verdadeiro, adiciona um prefixo aleatório aos arquivos contendo os recortes\n",
    "salvos. Útil para treinamento via MONAI Label, visto que o módulo separa os conjuntos de treino e validação alfabeticamente.\n",
    "\n",
    "@compact_rgb (bool): Default: False; Caso verdadeiro, salva a informação RGB do recorte não como 3 canais distintos, mas como\n",
    "1 único canal do tipo RGB, formato suportado pelo visualizador do 3D Slicer.\n",
    "\n",
    "@crop_soi_area (bool): Default: True; Caso verdadeiro, descarta a área não-útil ao redor do SOI antes de gerar os recortes.\n",
    "Caso contrário, considera as imagens completamente.\n",
    "\n",
    "@split_ec_instances (bool): Default: False; Caso falso, os elementos construtores são separados apenas por classe. Todos os\n",
    "elementos construtores da imagem são salvos em um únicoa arquivo, e todas as instâncias de um mesmo elemento têm o mesmo valor\n",
    "(correspondente ao seu índice em @unified_labels_file). Caso contrário, o arquivo final é salvo no formato (H, W, N), sendo\n",
    "N a quantidade de elementos construtores em @unified_labels_file. O elemento de índice k é salvo no canal k-1 desta nova\n",
    "dimensão, e cada instância tem um valor diferente.\n",
    "'''\n",
    "\n",
    "'''\n",
    "# ** For mineralogy\n",
    "gen_dataset(groups, dataset_dir, from_nc = from_nc, do_qemscan_unification = True, do_ec_unification = False,\n",
    "            unified_labels_file = unified_labels_file, extension = 'nii.gz', channel_first = False, as_volume = False,\n",
    "            initial_labels = None,\n",
    "            ds_image_size = 1000, show = True, save_nodes = [], calc_props = False, bg_thresh = 0, max_zero_rate_thresh = 0.3,\n",
    "            missing_nodes_allowed = ['ec'], final_size = None, single_output_dir = False, save_randomized = False,\n",
    "            compact_rgb = False, crop_soi_area = True, split_ec_instances = False, yolo = False)\n",
    "\n",
    "\n",
    "# ** For EC's\n",
    "gen_dataset(groups, os.path.join(dataset_dir, 'elementos_construtores', 'dataset_sdumont'), from_nc = from_nc, do_qemscan_unification = False, do_ec_unification = False,\n",
    "            unified_labels_file = unified_labels_file, extension = 'seg.nrrd', channel_first = False, as_volume = False,\n",
    "            initial_labels = None,\n",
    "            ds_image_size = 2048, show = False, save_nodes = ['px', 'ec'], calc_props = False, bg_thresh = 0, max_zero_rate_thresh = 1,\n",
    "            missing_nodes_allowed = ['pp', 'qemscan', 'ec'], final_size = None, single_output_dir = True, save_randomized = True,\n",
    "            compact_rgb = False, crop_soi_area = False, split_ec_instances = True, yolo = False)\n",
    "'''\n",
    "\n",
    "#groups = {\n",
    "#    'SC': ['6353.00t']\n",
    "#}\n",
    "\n",
    "# ** For EC's w/ yolo\n",
    "gen_dataset(groups, dataset_dir, from_nc = from_nc, do_qemscan_unification = False, do_ec_unification = False,\n",
    "            unified_labels_file = unified_labels_file, extension = 'png', channel_first = False, as_volume = False,\n",
    "            initial_labels = None,\n",
    "            ds_image_size = 2048, show = False, save_nodes = ['px', 'ec'], calc_props = False, bg_thresh = 0, max_zero_rate_thresh = 1,\n",
    "            missing_nodes_allowed = ['pp', 'qemscan', 'ec'], final_size = None, single_output_dir = False, save_randomized = True,\n",
    "            compact_rgb = False, crop_soi_area = False, split_ec_instances = True, yolo = True, yolo_seg = True,\n",
    "            occlusion_percentage = [0.5, 0.1, 0.8, 0.5, 0.1, 0.3, 0.5, 0.1, 0.1, 0.3, 0.5, 0.5, 0.5, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a05643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "m = torch.load('C:\\\\Users\\\\LTrace\\\\Desktop\\\\slicerltrace\\\\src\\\\ltrace\\\\ltrace\\\\' + \\\n",
    "    'assets\\\\trained_models\\\\ThinSectionEnv\\\\petrobras_complete_u_net.pth')#, map_location = 'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f688aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
